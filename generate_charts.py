#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCR Models Evaluation and Chart Generation Script
=================================================

‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• OCR ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü

‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö:
- base_model (EasyOCR ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô)
- custom_thai_1500_iteration (1.5K iterations)
- custom_thai_15000_iteration (15K iterations)

‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:
- data_from_web (300 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)
- data_from_outsource (300 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)

‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î:
- Character Accuracy & Error Rate (CER)
- Word Error Rate (WER) - Thai
- Semantic Similarity
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

def setup_plotting():
    """Configure matplotlib and seaborn settings for optimal chart appearance"""
    plt.style.use('default')
    sns.set_palette("husl")
    plt.rcParams['figure.figsize'] = (12, 8)
    plt.rcParams['font.size'] = 11
    plt.rcParams['axes.titlesize'] = 16
    plt.rcParams['axes.labelsize'] = 14
    plt.rcParams['xtick.labelsize'] = 12
    plt.rcParams['ytick.labelsize'] = 12
    plt.rcParams['legend.fontsize'] = 12
    plt.rcParams['figure.titlesize'] = 18
    plt.rcParams['savefig.dpi'] = 300
    plt.rcParams['savefig.bbox'] = 'tight'
    plt.rcParams['savefig.facecolor'] = 'white'
    print("‚úÖ Libraries ready")

def load_evaluation_data():
    """Load and preprocess OCR evaluation data"""
    try:
        df = pd.read_json('evaluation_results.json')
        print(f"üìä Loaded evaluation results: {len(df):,} records")
        
        # Data overview
        print("\nüìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ:")
        print(f"   - Number of models: {df['model_name'].nunique()}")
        print(f"   - Number of datasets: {df['dataset_name'].nunique()}")
        print(f"   - Models tested: {', '.join(df['model_name'].unique())}")
        print(f"   - Datasets tested: {', '.join(df['dataset_name'].unique())}")
        
        return df
    except FileNotFoundError:
        print("‚ùå Error: evaluation_results.json not found")
        raise

def calculate_summary_stats(df):
    """Calculate summary statistics for each model-dataset combination"""
    # Calculate character accuracy from cer_percent
    df['character_accuracy'] = 100 - df['cer_percent']
    
    summary_stats = df.groupby(['model_name', 'dataset_name']).agg({
        'character_accuracy': ['mean', 'std', 'count'],
        'cer_percent': ['mean', 'std'],
        'wer_percent': ['mean', 'std'],
        'wer_pythainlp_percent': ['mean', 'std'],
        'semantic_similarity': ['mean', 'std']
    }).round(4)
    
    # Flatten column names
    summary_stats.columns = ['_'.join(col).strip() for col in summary_stats.columns.values]
    summary_stats = summary_stats.reset_index()
    
    print("üìà Summary statistics calculated")
    return summary_stats

def prepare_pivot_tables(summary_stats):
    """Prepare pivot tables for visualization with proper model ordering"""
    # Define the desired model order
    model_order = ['base_model', 'custom_thai_1500_iteration', 'custom_thai_15000_iteration']
    
    pivot_cer = summary_stats.reset_index().pivot(
        index='model_name', 
        columns='dataset_name', 
        values='cer_percent_mean'
    )
    
    pivot_wer = summary_stats.reset_index().pivot(
        index='model_name', 
        columns='dataset_name', 
        values='wer_percent_mean'
    )
    
    pivot_wer_pythainlp = summary_stats.reset_index().pivot(
        index='model_name', 
        columns='dataset_name', 
        values='wer_pythainlp_percent_mean'
    )
    
    pivot_semantic = summary_stats.reset_index().pivot(
        index='model_name', 
        columns='dataset_name', 
        values='semantic_similarity_mean'
    )
    
    # Reorder index according to model_order
    pivot_cer = pivot_cer.reindex(index=model_order)
    pivot_wer = pivot_wer.reindex(index=model_order)
    pivot_wer_pythainlp = pivot_wer_pythainlp.reindex(index=model_order)
    pivot_semantic = pivot_semantic.reindex(index=model_order)
    
    return pivot_cer, pivot_wer, pivot_wer_pythainlp, pivot_semantic

def setup_report_directory():
    """Create and return the report directory path"""
    report_dir = Path("report")
    report_dir.mkdir(exist_ok=True)
    print(f"üìÅ Created folder: {report_dir.absolute()}")
    return report_dir

def save_cer_percent_chart(pivot_cer, report_dir):
    """Save Character Error Rate (CER) comparison chart"""
    # Create custom labels mapping
    model_labels = {
        'base_model': 'base',
        'custom_thai_1500_iteration': '1.5k',
        'custom_thai_15000_iteration': '15k'
    }
    
    # Rename index using the mapping
    pivot_renamed = pivot_cer.rename(index=model_labels)
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    pivot_renamed.plot(kind='barh', ax=ax, width=0.8, color=['lightpink', 'crimson'])
    ax.set_title('Character Error Rate (CER) Comparison', fontsize=16, pad=20)
    ax.set_xlabel('Character Error Rate (%)', fontsize=14)
    ax.set_ylabel('Model', fontsize=14)
    ax.legend(title='Dataset', fontsize=12)
    ax.grid(axis='x', alpha=0.3)
    ax.tick_params(axis='y', labelsize=12)
    ax.tick_params(axis='x', labelsize=12)
    for container in ax.containers:
        ax.bar_label(container, fmt='%.1f%%', padding=3, fontsize=10)
    
    plt.tight_layout()
    plt.savefig(report_dir / 'cer_percent_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   ‚úÖ Saved: cer_percent_comparison.png")
    
    # Create explanation text file
    explanation = """‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (CER)

‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£:
‚Ä¢ CER = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (%)
‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ (0% = ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
‚Ä¢ CER 5% = ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î 5 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏à‡∏≤‡∏Å 100 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
‚Ä¢ CER 10% = ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î 10 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏à‡∏≤‡∏Å 100 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
"""
    
    with open(report_dir / 'cer_percent_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(explanation)
    print("   ‚úÖ Saved: cer_percent_comparison.txt")

def save_wer_percent_chart(pivot_wer, report_dir):
    """Save Word Error Rate (WER) comparison chart"""
    model_labels = {
        'base_model': 'base',
        'custom_thai_1500_iteration': '1.5k',
        'custom_thai_15000_iteration': '15k'
    }
    
    pivot_renamed = pivot_wer.rename(index=model_labels)
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    pivot_renamed.plot(kind='barh', ax=ax, width=0.8, color=['orange', 'red'])
    ax.set_title('Word Error Rate (WER) Comparison', fontsize=16, pad=20)
    ax.set_xlabel('Word Error Rate (%)', fontsize=14)
    ax.set_ylabel('Model', fontsize=14)
    ax.legend(title='Dataset', fontsize=12)
    ax.grid(axis='x', alpha=0.3)
    ax.tick_params(axis='y', labelsize=12)
    ax.tick_params(axis='x', labelsize=12)
    for container in ax.containers:
        ax.bar_label(container, fmt='%.1f%%', padding=3, fontsize=10)
    
    plt.tight_layout()
    plt.savefig(report_dir / 'wer_percent_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   ‚úÖ Saved: wer_percent_comparison.png")
    
    explanation = """‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥ (WER)

‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£:
‚Ä¢ WER = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡∏≥ (%)
‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ (0% = ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
‚Ä¢ WER 5% = ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î 5 ‡∏Ñ‡∏≥‡∏à‡∏≤‡∏Å 100 ‡∏Ñ‡∏≥
‚Ä¢ WER 15% = ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î 15 ‡∏Ñ‡∏≥‡∏à‡∏≤‡∏Å 100 ‡∏Ñ‡∏≥
"""
    
    with open(report_dir / 'wer_percent_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(explanation)
    print("   ‚úÖ Saved: wer_percent_comparison.txt")

def save_semantic_similarity_chart(pivot_semantic, report_dir):
    """Save Semantic Similarity comparison chart"""
    model_labels = {
        'base_model': 'base',
        'custom_thai_1500_iteration': '1.5k',
        'custom_thai_15000_iteration': '15k'
    }
    
    pivot_renamed = pivot_semantic.rename(index=model_labels)
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    pivot_renamed.plot(kind='barh', ax=ax, width=0.8, color=['lightgreen', 'darkgreen'])
    ax.set_title('Semantic Similarity Comparison', fontsize=16, pad=20)
    ax.set_xlabel('Semantic Similarity Score', fontsize=14)
    ax.set_ylabel('Model', fontsize=14)
    ax.legend(title='Dataset', fontsize=12)
    ax.grid(axis='x', alpha=0.3)
    ax.tick_params(axis='y', labelsize=12)
    ax.tick_params(axis='x', labelsize=12)
    for container in ax.containers:
        ax.bar_label(container, fmt='%.3f', padding=3, fontsize=10)
    
    plt.tight_layout()
    plt.savefig(report_dir / 'semantic_similarity_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   ‚úÖ Saved: semantic_similarity_comparison.png")
    
    explanation = """‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (Semantic Similarity)

‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£:
‚Ä¢ ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (0.0-1.0)
‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ (1.0 = ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
‚Ä¢ 0.9 = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏°‡∏≤‡∏Å
‚Ä¢ 0.5 = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á
‚Ä¢ 0.1 = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å
"""
    
    with open(report_dir / 'semantic_similarity_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(explanation)
    print("   ‚úÖ Saved: semantic_similarity_comparison.txt")

def save_wer_pythainlp_percent_chart(pivot_wer_pythainlp, report_dir):
    """Save Word Error Rate (PyThaiNLP) comparison chart"""
    # Create custom labels mapping
    model_labels = {
        'base_model': 'base',
        'custom_thai_1500_iteration': '1.5k',
        'custom_thai_15000_iteration': '15k'
    }
    
    # Rename index using the mapping
    pivot_renamed = pivot_wer_pythainlp.rename(index=model_labels)
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    pivot_renamed.plot(kind='barh', ax=ax, width=0.8, color=['lightblue', 'navy'])
    ax.set_title('Word Error Rate (PyThaiNLP) Comparison', fontsize=16, pad=20)
    ax.set_xlabel('Word Error Rate (%)', fontsize=14)
    ax.set_ylabel('Model', fontsize=14)
    ax.legend(title='Dataset', fontsize=12)
    ax.grid(axis='x', alpha=0.3)
    ax.tick_params(axis='y', labelsize=12)
    ax.tick_params(axis='x', labelsize=12)
    for container in ax.containers:
        ax.bar_label(container, fmt='%.1f%%', padding=3, fontsize=10)
    
    plt.tight_layout()
    plt.savefig(report_dir / 'wer_pythainlp_percent_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   ‚úÖ Saved: wer_pythainlp_percent_comparison.png")
    
    # Create explanation text file
    explanation = """‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥ (WER-Thai)

‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£:
‚Ä¢ WER ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö PyThaiNLP
‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ (0% = ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö)

‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á:
‚Ä¢ ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Å‡∏ß‡πà‡∏≤ WER ‡∏õ‡∏Å‡∏ï‡∏¥
‚Ä¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞
"""
    
    with open(report_dir / 'wer_pythainlp_percent_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(explanation)
    print("   ‚úÖ Saved: wer_pythainlp_percent_comparison.txt")

def generate_insights(summary_stats):
    """Generate key insights from the evaluation"""
    print("\nüîç ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:")
    print("="*50)
    
    # Find best performing model per dataset
    print("\nüèÜ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
    for dataset in summary_stats['dataset_name'].unique():
        dataset_data = summary_stats[summary_stats['dataset_name'] == dataset]
        best_model = dataset_data.loc[dataset_data['character_accuracy_mean'].idxmax()]
        dataset_name = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡πá‡∏ö" if dataset == 'data_from_web' else "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡πâ‡∏≤‡∏á‡∏á‡∏≤‡∏ô"
        print(f"   üìä {dataset_name}: {best_model['model_name']} ({best_model['character_accuracy_mean']:.1f}%)")
    
    print("\nüí° ‡∏Ç‡πâ‡∏≠‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï:")
    print("   ‚Ä¢ ‡πÇ‡∏°‡πÄ‡∏î‡∏• Custom ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å")
    print("   ‚Ä¢ ‡πÇ‡∏°‡πÄ‡∏î‡∏• Base ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤") 
    print("   ‚Ä¢ ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° iteration ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û")

def export_results(df, summary_stats):
    """Export results to CSV files"""
    summary_stats.to_csv('ocr_evaluation_summary.csv', index=False)
    df.to_csv('ocr_evaluation_detailed.csv', index=False)
    
    # Create simple summary
    summary_data = {
        'total_samples': len(df),
        'models_tested': df['model_name'].unique().tolist(),
        'datasets_tested': df['dataset_name'].unique().tolist()
    }
    
    # Add best model per dataset
    for dataset in summary_stats['dataset_name'].unique():
        dataset_data = summary_stats[summary_stats['dataset_name'] == dataset]
        best_model = dataset_data.loc[dataset_data['character_accuracy_mean'].idxmax()]
        summary_data[f'best_{dataset}'] = {
            'model': best_model['model_name'],
            'accuracy': float(best_model['character_accuracy_mean'])
        }
    
    with open('evaluation_final_summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary_data, f, indent=2, ensure_ascii=False)
    
    print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
    print("   üìÅ ocr_evaluation_summary.csv")
    print("   üìÅ ocr_evaluation_detailed.csv")
    print("   üìÅ evaluation_final_summary.json")

def print_final_summary(report_dir):
    """Print final summary of generated files"""
    chart_files = list(report_dir.glob("*.png"))
    text_files = list(report_dir.glob("*.txt"))
    
    print("\nüéâ ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü:")
    print("="*40)
    print(f"üìä ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á: {len(chart_files)} ‡πÑ‡∏ü‡∏•‡πå")
    print(f"üìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: {len(text_files)} ‡πÑ‡∏ü‡∏•‡πå")
    print(f"üìÅ ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: {report_dir.name}/")
    print("üíæ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û: 300 DPI (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏π‡∏á)")

def main():
    """Main function to execute the analysis"""
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• OCR ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü")
    print("="*50)
    
    # 1. Setup
    setup_plotting()
    
    # 2. Load and prepare data
    df = load_evaluation_data()
    summary_stats = calculate_summary_stats(df)
    pivot_cer, pivot_wer, pivot_wer_pythainlp, pivot_semantic = prepare_pivot_tables(summary_stats)
    
    # 3. Setup report directory
    report_dir = setup_report_directory()
    
    # 4. Generate charts
    print("\nüíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü:")
    save_cer_percent_chart(pivot_cer, report_dir)
    save_wer_percent_chart(pivot_wer, report_dir) 
    save_wer_pythainlp_percent_chart(pivot_wer_pythainlp, report_dir)
    save_semantic_similarity_chart(pivot_semantic, report_dir)
    
    # 5. Generate insights
    generate_insights(summary_stats)
    
    # 6. Export results
    export_results(df, summary_stats)
    
    # 7. Print summary
    print_final_summary(report_dir)
    
    print("\n‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! üéâ")

if __name__ == "__main__":
    main()
