#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCR Models Evaluation and Chart Generation Script
=================================================

‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• OCR ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü

‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö:
- ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå evaluation_results.json ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:
- data_from_web (300 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)
- data_from_outsource (300 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)

‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î:
- Character Accuracy & Error Rate (CER)
- Word Error Rate (WER) - Thai
- Semantic Similarity
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

def setup_plotting():
    """Configure matplotlib and seaborn settings for optimal chart appearance"""
    plt.style.use('default')
    sns.set_palette("husl")
    plt.rcParams['figure.figsize'] = (12, 8)
    plt.rcParams['font.size'] = 11
    plt.rcParams['axes.titlesize'] = 16
    plt.rcParams['axes.labelsize'] = 14
    plt.rcParams['xtick.labelsize'] = 12
    plt.rcParams['ytick.labelsize'] = 12
    plt.rcParams['legend.fontsize'] = 12
    plt.rcParams['figure.titlesize'] = 18
    plt.rcParams['savefig.dpi'] = 300
    plt.rcParams['savefig.bbox'] = 'tight'
    plt.rcParams['savefig.facecolor'] = 'white'
    print("‚úÖ Libraries ready")

def create_model_labels(model_names):
    """Create shortened labels for model names for better chart readability"""
    model_labels = {}
    for model_name in model_names:
        if model_name == 'base_model':
            model_labels[model_name] = 'base'
        elif model_name == "out_source_merge_kaggle_data_3gpus":
            model_labels[model_name] = 'merge_kaggle'
        elif model_name == "out_source_merge_kaggle_data_freeze_sequence_config_3gpus":
            model_labels[model_name] = 'freeze_seq'
        elif model_name == "out_source_only_data_3gpus":
            model_labels[model_name] = 'only_data'
        else:
            model_labels[model_name] = model_name.replace('_', ' ')[:15]
    
    return model_labels

def load_evaluation_data(file_path):
    """Load and preprocess OCR evaluation data"""
    try:
        df = pd.read_json(file_path)
        print(f"üìä Loaded evaluation results: {len(df):,} records")
        
        # Data overview
        print("\nüìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ:")
        print(f"   - Number of models: {df['model_name'].nunique()}")
        print(f"   - Number of datasets: {df['dataset_name'].nunique()}")
        print(f"   - Models tested: {', '.join(df['model_name'].unique())}")
        print(f"   - Datasets tested: {', '.join(df['dataset_name'].unique())}")
        
        return df
    except FileNotFoundError:
        print("‚ùå Error: evaluation_results.json not found")
        raise

def calculate_summary_stats(df):
    """Calculate summary statistics for each model-dataset combination"""
    # Calculate character accuracy from cer_percent
    df['character_accuracy'] = 100 - df['cer_percent']
    
    summary_stats = df.groupby(['model_name', 'dataset_name']).agg({
        'character_accuracy': ['mean', 'std', 'count'],
        'cer_percent': ['mean', 'std'],
        'wer_percent': ['mean', 'std'],
        'wer_pythainlp_percent': ['mean', 'std'],
        'semantic_similarity': ['mean', 'std']
    }).round(4)
    
    # Flatten column names
    summary_stats.columns = ['_'.join(col).strip() for col in summary_stats.columns.values]
    summary_stats = summary_stats.reset_index()
    
    print("üìà Summary statistics calculated")
    return summary_stats

def prepare_pivot_tables(summary_stats):
    """Prepare pivot tables for visualization with proper model ordering"""
    # Get model order from the data, with base_model first
    all_models = summary_stats['model_name'].unique()
    model_order = ['base_model'] + [model for model in all_models if model != 'base_model']
    
    pivot_cer = summary_stats.reset_index().pivot(
        index='model_name', 
        columns='dataset_name', 
        values='cer_percent_mean'
    )
    
    pivot_wer = summary_stats.reset_index().pivot(
        index='model_name', 
        columns='dataset_name', 
        values='wer_percent_mean'
    )
    
    pivot_wer_pythainlp = summary_stats.reset_index().pivot(
        index='model_name', 
        columns='dataset_name', 
        values='wer_pythainlp_percent_mean'
    )
    
    pivot_semantic = summary_stats.reset_index().pivot(
        index='model_name', 
        columns='dataset_name', 
        values='semantic_similarity_mean'
    )
    
    # Reorder index according to model_order (only for models that exist in the data)
    existing_models = [model for model in model_order if model in pivot_cer.index]
    pivot_cer = pivot_cer.reindex(index=existing_models)
    pivot_wer = pivot_wer.reindex(index=existing_models)
    pivot_wer_pythainlp = pivot_wer_pythainlp.reindex(index=existing_models)
    pivot_semantic = pivot_semantic.reindex(index=existing_models)
    
    return pivot_cer, pivot_wer, pivot_wer_pythainlp, pivot_semantic

def setup_report_directory():
    """Create and return the report directory path with timestamp"""
    from datetime import datetime
    
    # Create timestamp for unique folder name
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_dir = Path(f"reports/ocr_evaluation_{timestamp}")
    report_dir.mkdir(parents=True, exist_ok=True)
    
    # Create subdirectories for better organization
    charts_dir = report_dir / "charts"
    charts_dir.mkdir(exist_ok=True)
    
    explanations_dir = report_dir / "explanations"
    explanations_dir.mkdir(exist_ok=True)
    
    data_dir = report_dir / "data"
    data_dir.mkdir(exist_ok=True)
    
    print(f"üìÅ Created organized report structure:")
    print(f"   üìä Charts: {charts_dir}")
    print(f"   üìù Explanations: {explanations_dir}")
    print(f"   üìä Data: {data_dir}")
    
    return report_dir, charts_dir, explanations_dir, data_dir

def save_cer_percent_chart(pivot_cer, charts_dir, explanations_dir):
    """Save Character Error Rate (CER) comparison chart"""
    # Create custom labels mapping - dynamically generate from actual model names
    model_labels = create_model_labels(pivot_cer.index)
    
    # Rename index using the mapping
    pivot_renamed = pivot_cer.rename(index=model_labels)
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    pivot_renamed.plot(kind='barh', ax=ax, width=0.8, color=['lightpink', 'crimson'])
    ax.set_title('Character Error Rate (CER) Comparison', fontsize=16, pad=20)
    ax.set_xlabel('Character Error Rate (%)', fontsize=14)
    ax.set_ylabel('Model', fontsize=14)
    ax.legend(title='Dataset', fontsize=12)
    ax.grid(axis='x', alpha=0.3)
    ax.tick_params(axis='y', labelsize=12)
    ax.tick_params(axis='x', labelsize=12)
    for container in ax.containers:
        ax.bar_label(container, fmt='%.1f%%', padding=3, fontsize=10)
    
    plt.tight_layout()
    plt.savefig(charts_dir / 'cer_percent_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   ‚úÖ Saved: charts/cer_percent_comparison.png")
    
    # Create explanation text file
    explanation = """‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (CER)

‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£:
‚Ä¢ CER = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (%)
‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ (0% = ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
‚Ä¢ CER 5% = ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î 5 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏à‡∏≤‡∏Å 100 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
‚Ä¢ CER 10% = ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î 10 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏à‡∏≤‡∏Å 100 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
"""
    
    with open(explanations_dir / 'cer_percent_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(explanation)
    print("   ‚úÖ Saved: explanations/cer_percent_comparison.txt")

def save_wer_percent_chart(pivot_wer, charts_dir, explanations_dir):
    """Save Word Error Rate (WER) comparison chart"""
    # Create custom labels mapping - dynamically generate from actual model names
    model_labels = create_model_labels(pivot_wer.index)
    
    pivot_renamed = pivot_wer.rename(index=model_labels)
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    pivot_renamed.plot(kind='barh', ax=ax, width=0.8, color=['orange', 'red'])
    ax.set_title('Word Error Rate (WER) Comparison', fontsize=16, pad=20)
    ax.set_xlabel('Word Error Rate (%)', fontsize=14)
    ax.set_ylabel('Model', fontsize=14)
    ax.legend(title='Dataset', fontsize=12)
    ax.grid(axis='x', alpha=0.3)
    ax.tick_params(axis='y', labelsize=12)
    ax.tick_params(axis='x', labelsize=12)
    for container in ax.containers:
        ax.bar_label(container, fmt='%.1f%%', padding=3, fontsize=10)
    
    plt.tight_layout()
    plt.savefig(charts_dir / 'wer_percent_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   ‚úÖ Saved: charts/wer_percent_comparison.png")
    
    explanation = """‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥ (WER)

‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£:
‚Ä¢ WER = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡∏≥ (%)
‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ (0% = ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
‚Ä¢ WER 5% = ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î 5 ‡∏Ñ‡∏≥‡∏à‡∏≤‡∏Å 100 ‡∏Ñ‡∏≥
‚Ä¢ WER 15% = ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î 15 ‡∏Ñ‡∏≥‡∏à‡∏≤‡∏Å 100 ‡∏Ñ‡∏≥
"""
    
    with open(explanations_dir / 'wer_percent_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(explanation)
    print("   ‚úÖ Saved: explanations/wer_percent_comparison.txt")

def save_semantic_similarity_chart(pivot_semantic, charts_dir, explanations_dir):
    """Save Semantic Similarity comparison chart"""
    # Create custom labels mapping - dynamically generate from actual model names
    model_labels = create_model_labels(pivot_semantic.index)
    
    pivot_renamed = pivot_semantic.rename(index=model_labels)
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    pivot_renamed.plot(kind='barh', ax=ax, width=0.8, color=['lightgreen', 'darkgreen'])
    ax.set_title('Semantic Similarity Comparison', fontsize=16, pad=20)
    ax.set_xlabel('Semantic Similarity Score', fontsize=14)
    ax.set_ylabel('Model', fontsize=14)
    ax.legend(title='Dataset', fontsize=12)
    ax.grid(axis='x', alpha=0.3)
    ax.tick_params(axis='y', labelsize=12)
    ax.tick_params(axis='x', labelsize=12)
    for container in ax.containers:
        ax.bar_label(container, fmt='%.3f', padding=3, fontsize=10)
    
    plt.tight_layout()
    plt.savefig(charts_dir / 'semantic_similarity_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   ‚úÖ Saved: charts/semantic_similarity_comparison.png")
    
    explanation = """‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (Semantic Similarity)

‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£:
‚Ä¢ ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (0.0-1.0)
‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ (1.0 = ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
‚Ä¢ 0.9 = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏°‡∏≤‡∏Å
‚Ä¢ 0.5 = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á
‚Ä¢ 0.1 = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å
"""
    
    with open(explanations_dir / 'semantic_similarity_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(explanation)
    print("   ‚úÖ Saved: explanations/semantic_similarity_comparison.txt")

def save_wer_pythainlp_percent_chart(pivot_wer_pythainlp, charts_dir, explanations_dir):
    """Save Word Error Rate (PyThaiNLP) comparison chart"""
    # Create custom labels mapping - dynamically generate from actual model names
    model_labels = create_model_labels(pivot_wer_pythainlp.index)
    
    # Rename index using the mapping
    pivot_renamed = pivot_wer_pythainlp.rename(index=model_labels)
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    pivot_renamed.plot(kind='barh', ax=ax, width=0.8, color=['lightblue', 'navy'])
    ax.set_title('Word Error Rate (PyThaiNLP) Comparison', fontsize=16, pad=20)
    ax.set_xlabel('Word Error Rate (%)', fontsize=14)
    ax.set_ylabel('Model', fontsize=14)
    ax.legend(title='Dataset', fontsize=12)
    ax.grid(axis='x', alpha=0.3)
    ax.tick_params(axis='y', labelsize=12)
    ax.tick_params(axis='x', labelsize=12)
    for container in ax.containers:
        ax.bar_label(container, fmt='%.1f%%', padding=3, fontsize=10)
    
    plt.tight_layout()
    plt.savefig(charts_dir / 'wer_pythainlp_percent_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   ‚úÖ Saved: charts/wer_pythainlp_percent_comparison.png")
    
    # Create explanation text file
    explanation = """‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥ (WER-Thai)

‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£:
‚Ä¢ WER ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö PyThaiNLP
‚Ä¢ ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ (0% = ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö)

‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á:
‚Ä¢ ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Å‡∏ß‡πà‡∏≤ WER ‡∏õ‡∏Å‡∏ï‡∏¥
‚Ä¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞
"""
    
    with open(explanations_dir / 'wer_pythainlp_percent_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(explanation)
    print("   ‚úÖ Saved: explanations/wer_pythainlp_percent_comparison.txt")

def generate_insights(summary_stats):
    """Generate key insights from the evaluation"""
    print("\nüîç ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:")
    print("="*50)
    
    # Find best performing model per dataset
    print("\nüèÜ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
    for dataset in summary_stats['dataset_name'].unique():
        dataset_data = summary_stats[summary_stats['dataset_name'] == dataset]
        best_model = dataset_data.loc[dataset_data['character_accuracy_mean'].idxmax()]
        dataset_name = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡πá‡∏ö" if dataset == 'data_from_web' else "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡πâ‡∏≤‡∏á‡∏á‡∏≤‡∏ô"
        print(f"   üìä {dataset_name}: {best_model['model_name']} ({best_model['character_accuracy_mean']:.1f}%)")
    
    print("\nüí° ‡∏Ç‡πâ‡∏≠‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï:")
    print("   ‚Ä¢ ‡πÇ‡∏°‡πÄ‡∏î‡∏• Custom ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å")
    print("   ‚Ä¢ ‡πÇ‡∏°‡πÄ‡∏î‡∏• Base ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤") 
    print("   ‚Ä¢ ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° iteration ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û")

def export_results(df, summary_stats, data_dir):
    """Export results to CSV files"""
    summary_stats.to_csv(data_dir / 'ocr_evaluation_summary.csv', index=False)
    df.to_csv(data_dir / 'ocr_evaluation_detailed.csv', index=False)
    
    # Create simple summary
    summary_data = {
        'total_samples': len(df),
        'models_tested': df['model_name'].unique().tolist(),
        'datasets_tested': df['dataset_name'].unique().tolist()
    }
    
    # Add best model per dataset
    for dataset in summary_stats['dataset_name'].unique():
        dataset_data = summary_stats[summary_stats['dataset_name'] == dataset]
        best_model = dataset_data.loc[dataset_data['character_accuracy_mean'].idxmax()]
        summary_data[f'best_{dataset}'] = {
            'model': best_model['model_name'],
            'accuracy': float(best_model['character_accuracy_mean'])
        }
    
    with open(data_dir / 'evaluation_final_summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary_data, f, indent=2, ensure_ascii=False)
    
    print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
    print("   üìÅ data/ocr_evaluation_summary.csv")
    print("   üìÅ data/ocr_evaluation_detailed.csv")
    print("   üìÅ data/evaluation_final_summary.json")

def print_final_summary(report_dir, charts_dir, explanations_dir, data_dir):
    """Print final summary of generated files"""
    chart_files = list(charts_dir.glob("*.png"))
    text_files = list(explanations_dir.glob("*.txt"))
    data_files = list(data_dir.glob("*"))
    
    print("\nüéâ ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü:")
    print("="*40)
    print(f"üìä ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á: {len(chart_files)} ‡πÑ‡∏ü‡∏•‡πå")
    print(f"üìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: {len(text_files)} ‡πÑ‡∏ü‡∏•‡πå")
    print(f"üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(data_files)} ‡πÑ‡∏ü‡∏•‡πå")
    print(f"üìÅ ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: {report_dir.name}/")
    print("üíæ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û: 300 DPI (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏π‡∏á)")
    
    print(f"\nüìÇ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå:")
    print(f"   üìä Charts: {charts_dir}")
    print(f"   üìù Explanations: {explanations_dir}")
    print(f"   üìä Data: {data_dir}")

def main():
    """Main function to execute the analysis"""
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• OCR ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü")
    print("="*50)
    
    # 1. Setup
    setup_plotting()
    
    # 2. Load and prepare data
    df = load_evaluation_data('output/evaluation_results.json')
    summary_stats = calculate_summary_stats(df)
    pivot_cer, pivot_wer, pivot_wer_pythainlp, pivot_semantic = prepare_pivot_tables(summary_stats)
    
    # 3. Setup report directory
    report_dir, charts_dir, explanations_dir, data_dir = setup_report_directory()
    
    # 4. Generate charts
    print("\nüíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü:")
    save_cer_percent_chart(pivot_cer, charts_dir, explanations_dir)
    save_wer_percent_chart(pivot_wer, charts_dir, explanations_dir) 
    save_wer_pythainlp_percent_chart(pivot_wer_pythainlp, charts_dir, explanations_dir)
    save_semantic_similarity_chart(pivot_semantic, charts_dir, explanations_dir)
    
    # 5. Generate insights
    generate_insights(summary_stats)
    
    # 6. Export results
    export_results(df, summary_stats, data_dir)
    
    # 7. Print summary
    print_final_summary(report_dir, charts_dir, explanations_dir, data_dir)
    
    print("\n‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! üéâ")

if __name__ == "__main__":
    main()
